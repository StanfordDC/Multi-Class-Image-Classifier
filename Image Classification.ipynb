{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f99615",
   "metadata": {},
   "source": [
    "## Import train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66390f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/test_folder'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copytree('/common/scratch/projectgrps/CS424/assets/20230216/test_', 'test/test_folder')\n",
    "shutil.copytree('/common/scratch/projectgrps/CS424/assets/20230216/train_', 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4865f2",
   "metadata": {},
   "source": [
    "## Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da84a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 18:50:14.643060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 18:50:19.456655: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/cuDNN/8.1.1.33-CUDA-11.2.2/lib:/opt/apps/software/CUDA/11.2.2/nvvm/lib64:/opt/apps/software/CUDA/11.2.2/extras/CUPTI/lib64:/opt/apps/software/CUDA/11.2.2/lib:/opt/apps/software/Python/3.7.13-GCCcore-11.2.0/lib:/opt/apps/software/OpenSSL/1.1/lib:/opt/apps/software/libffi/3.4.2-GCCcore-11.2.0/lib64:/opt/apps/software/GMP/6.2.1-GCCcore-11.2.0/lib:/opt/apps/software/XZ/5.2.5-GCCcore-11.2.0/lib:/opt/apps/software/SQLite/3.36-GCCcore-11.2.0/lib:/opt/apps/software/Tcl/8.6.11-GCCcore-11.2.0/lib:/opt/apps/software/libreadline/8.1-GCCcore-11.2.0/lib:/opt/apps/software/ncurses/6.2-GCCcore-11.2.0/lib:/opt/apps/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/opt/apps/software/binutils/2.37-GCCcore-11.2.0/lib:/opt/apps/software/zlib/1.2.11-GCCcore-11.2.0/lib:/opt/apps/software/GCCcore/11.2.0/lib64\n",
      "2023-03-26 18:50:19.456903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/cuDNN/8.1.1.33-CUDA-11.2.2/lib:/opt/apps/software/CUDA/11.2.2/nvvm/lib64:/opt/apps/software/CUDA/11.2.2/extras/CUPTI/lib64:/opt/apps/software/CUDA/11.2.2/lib:/opt/apps/software/Python/3.7.13-GCCcore-11.2.0/lib:/opt/apps/software/OpenSSL/1.1/lib:/opt/apps/software/libffi/3.4.2-GCCcore-11.2.0/lib64:/opt/apps/software/GMP/6.2.1-GCCcore-11.2.0/lib:/opt/apps/software/XZ/5.2.5-GCCcore-11.2.0/lib:/opt/apps/software/SQLite/3.36-GCCcore-11.2.0/lib:/opt/apps/software/Tcl/8.6.11-GCCcore-11.2.0/lib:/opt/apps/software/libreadline/8.1-GCCcore-11.2.0/lib:/opt/apps/software/ncurses/6.2-GCCcore-11.2.0/lib:/opt/apps/software/bzip2/1.0.8-GCCcore-11.2.0/lib:/opt/apps/software/binutils/2.37-GCCcore-11.2.0/lib:/opt/apps/software/zlib/1.2.11-GCCcore-11.2.0/lib:/opt/apps/software/GCCcore/11.2.0/lib64\n",
      "2023-03-26 18:50:19.456915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7819 images belonging to 124 classes.\n",
      "Found 1902 images belonging to 124 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 18:50:27.954379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 18:50:28.704162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9625 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:88:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 18:50:46.150310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2023-03-26 18:50:48.022324: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:50:48.022419: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.88GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:50:48.044056: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1cfb3350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-26 18:50:48.044098: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2023-03-26 18:50:48.051810: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-26 18:50:48.228188: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-03-26 18:50:48.754346: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:50:48.754421: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:50:48.766195: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.92GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:50:48.766244: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.92GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/244 [=======================>......] - ETA: 1:15 - loss: 3.5194 - accuracy: 0.2723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 18:57:11.975063: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:57:11.975150: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:57:11.988911: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.77GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-26 18:57:11.988952: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.77GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 581s 2s/step - loss: 3.2862 - accuracy: 0.3174 - val_loss: 1.6664 - val_accuracy: 0.6151\n",
      "Epoch 2/10\n",
      "244/244 [==============================] - 560s 2s/step - loss: 1.3402 - accuracy: 0.7069 - val_loss: 0.6879 - val_accuracy: 0.8386\n",
      "Epoch 3/10\n",
      "244/244 [==============================] - 567s 2s/step - loss: 0.6589 - accuracy: 0.8515 - val_loss: 0.3874 - val_accuracy: 0.9054\n",
      "Epoch 4/10\n",
      "244/244 [==============================] - 572s 2s/step - loss: 0.3951 - accuracy: 0.9050 - val_loss: 0.2978 - val_accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "244/244 [==============================] - 582s 2s/step - loss: 0.2684 - accuracy: 0.9354 - val_loss: 0.2688 - val_accuracy: 0.9222\n",
      "Epoch 6/10\n",
      "244/244 [==============================] - 571s 2s/step - loss: 0.1939 - accuracy: 0.9518 - val_loss: 0.2215 - val_accuracy: 0.9422\n",
      "Epoch 7/10\n",
      "244/244 [==============================] - 552s 2s/step - loss: 0.1514 - accuracy: 0.9619 - val_loss: 0.2528 - val_accuracy: 0.9364\n",
      "Epoch 8/10\n",
      "244/244 [==============================] - 587s 2s/step - loss: 0.1194 - accuracy: 0.9682 - val_loss: 0.2422 - val_accuracy: 0.9322\n",
      "Epoch 9/10\n",
      "244/244 [==============================] - 581s 2s/step - loss: 0.0916 - accuracy: 0.9774 - val_loss: 0.2381 - val_accuracy: 0.9411\n",
      "Epoch 10/10\n",
      "244/244 [==============================] - 595s 2s/step - loss: 0.0771 - accuracy: 0.9804 - val_loss: 0.2229 - val_accuracy: 0.9453\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers, losses\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "input_tensor  = Input(shape=(224,224,3))\n",
    "img_size      = (224, 224)\n",
    "batch_size    = 32  \n",
    "num_epochs    = 10\n",
    "learning_rate = 0.0001\n",
    "\n",
    "base_dir = \"train\"\n",
    "\n",
    "img_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=50,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip = True ,\n",
    "                    vertical_flip = True ,\n",
    "                    fill_mode='nearest',\n",
    "                    validation_split=0.2)\n",
    "\n",
    "\n",
    "train_generator = img_datagen.flow_from_directory(\n",
    "        base_dir,  \n",
    "        target_size=img_size,  \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical',\n",
    "        subset='training') \n",
    " \n",
    "validation_generator = img_datagen.flow_from_directory(\n",
    "        base_dir, \n",
    "        target_size=img_size, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical',\n",
    "        subset='validation') \n",
    "\n",
    "base_model = Xception(weights='imagenet',include_top=False,\n",
    "                      pooling='avg',input_shape=(224, 224, 3))\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(124, activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "steps_per_epoch=train_generator.n/batch_size\n",
    "validation_steps=validation_generator.n/batch_size\n",
    "\n",
    "result = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      epochs=num_epochs, \n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_steps,\n",
    "      verbose=1, \n",
    "      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086280f8",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daf68561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310edbb",
   "metadata": {},
   "source": [
    "## Predict test dataset using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3e2463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2005 images belonging to 1 classes.\n",
      "2005/2005 [==============================] - 115s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Softmax\n",
    "probability_model = Sequential([model, Softmax()])\n",
    "\n",
    "test_dir = \"test\"\n",
    "test_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "test_generator.reset()\n",
    "\n",
    "predictions = probability_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0737bf7",
   "metadata": {},
   "source": [
    "## Map each image to the category and put in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140a1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mapping = []\n",
    "for i in range (2005):\n",
    "    confidence = np.max(predictions[i])\n",
    "    if confidence < 0.01:\n",
    "        mapping.append(124)\n",
    "    else:\n",
    "        mapping.append(np.argmax(predictions[i]))\n",
    "        \n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"id\":filenames,\n",
    "                      \"category\":mapping})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
